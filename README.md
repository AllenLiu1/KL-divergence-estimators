# KL divergence estimators

Here I test a few implementations of a KL-divergence estimator
based on k-Nearest-Neighbours probability density estimation.

The estimator is that of 

>> Qing Wang, Sanjeev R. Kulkarni, and Sergio VerdÃº. "Divergence estimation for multidimensional densities via k-nearest-neighbor distances." Information Theory, IEEE Transactions on 55.5 (2009): 2392-2405.

## Requirements

- Python >= 3.6
- scipy, scikit-learn 
- slaypni/universal-divergence
